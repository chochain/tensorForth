.( ## GAN linear regression tests ) cr
100 constant N                             \ mini-batch size

N 2 1 1 nn.model                           \ generator
2 linear                                   \ w=2x2 bias=1.0
constant G

N 2 1 1 nn.model                           \ discriminator
5 linear 0.2 leakyrelu
3 linear 0.2 leakyrelu
1 linear sigmoid
constant D

: X N 2 matrix randn ;                     \ random input points
2 2 matrix{ 1 2 -0.1 0.5 } constant A      \ linear slopes
N 2 matrix ones
2 2 matrix{ 1 0 0 2 } @= constant b        \ offset (broadcast)
: Y X A @= b += ;                          \ Y = AX + b as real data points

N 1 1 1 tensor ones constant  REAL
N 1 1 1 tensor zeros constant FAKE

: gen ( -- t )
  G X 2 *= forward -1 n@ swap drop ;

0 constant _g
0 constant _r
0 constant _f
: run ( -- )
  D 1 trainable
  Y   forward REAL loss.bce [to] _r REAL backprop   \ treat real as real
  gen forward FAKE loss.bce [to] _f FAKE backprop   \ treat fake as fake
  0.001 nn.adam                                     \ train D (b1=0.9,b2=0.999)
  0 trainable
  gen forward REAL loss.bce [to] _g REAL backprop   \ treat fake as real
  1 n@ G swap ( D G t ) backprop                    \ pass dX to G
  0.001 nn.adam                                     \ train G
  drop drop pause                                   \ switch task and flush
  ;
\ expected loss G=>low, Dr=>low, Df=>high (thinking fake as real)  
: stat ( -- )
  cr ." w,b=" G 1 nn.w . 1 nn.b . drop
  ." G=" _g . ." , Dr=" _r . ." , Df=" _f . cr ;

: epoch ( -- ) 99 for run next stat ;               \ train with 100 * N samples
: gan ( n -- ) 
  for epoch next
  gen N 2 reshape2 s" jk" save                      \ generate N samples
  ;

9 gan
bye
